---
title: "Inference for Regression"
institute: "STAT 20 UC Berkeley"
logo: "images/stat20-hex.png"
format: 
  revealjs:
    theme: "../../assets/stat20.scss"
    highlight-style: breezedark
    slide-number: true
    incremental: true
    menu: false
    title-slide-attributes:
      data-background-image: "images/hex-background.png"
      data-background-size: cover  
    progress: false
execute:
  freeze: auto
---

```{r include = FALSE}
library(tidyverse)
library(patchwork)
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center")
set.seed(80)
```

<br>
<br>
<br>
<br>

<center>
[Some chatter from the internets]{.smalladage}

<br>
<br>
<br>
(Take out a piece of paper / pencil or tablet)
</center>


## 2016 Election

```{r out.width=700, echo = FALSE, fig.align='center'}
knitr::include_graphics("images/538.png")
```

. . .

**Question at hand**: How will Obama's 46% approval rating effect his
party's candidate for the 2016 presidential election?


## {}

```{r out.width=700, echo = FALSE, fig.align='center'}
knitr::include_graphics("images/538-1.png")
```


## {}

```{r out.width=700, echo = FALSE, fig.align='center'}
knitr::include_graphics("images/538-2.png")
```

. . .

::: poll
::: nonincremental
1. Sketch the data frame that Harry is talking about.
2. Sketch a plot of the trend he is describing.

You will have 2 minutes to work solo/silently, then 1 minute to discuss.
:::
:::

```{r echo = FALSE}
countdown::countdown(3, warn_when = 20, font_size = "1.5em")
```


## {}

```{r out.width=700, echo = FALSE, fig.align='center'}
knitr::include_graphics("images/538-3.png")
```

. . .

> Why is it ridiculous?


## Inference for Regression

. . .

We can fit a line through any cloud of points that we please, but if we
just have a *sample* of data, any trend we detect doesn't necessarily 
demonstrate that the trend exists in the *population* at large.


## Plato's Allegory of the Cave

. . .

```{r out.width=850, echo = FALSE, fig.align='center'}
knitr::include_graphics("images/plato-cave.jpg")
```


## Statistical Inference

. . .

**Goal**: use *statistics* calculated from data to makes inferences about the 
nature of *parameters*.

. . .

In regression,

::: nonincremental
- parameters: $\beta_0$, $\beta_1$
- statistics: $b_0$, $b_1$
:::

. . .

Classical tools of inference:

::: nonincremental
- Confidence Intervals
- Hypothesis Tests
:::


## Unemployment and elections

. . .

```{r echo = FALSE}
library(openintro)
data(unempl)
data(house)
data(president); pres <- president
year   <- seq(1898, 2010, 4)+1
n      <- length(year)
unemp  <- rep(0, n)
change <- rep(0, n)
presid <- rep("", n)
party  <- rep("", n)
for(i in 1:n){
	urow <- which(unempl$year == year[i]-1)
	if(i < n){
		prow <- which(pres$end > year[i])[1]
	} else {
		prow <- which(pres$potus == "Barack Obama")
	}
	hrow <- which(house$year_end >= year[i])[1]
	party[i] <- as.character(pres$party[prow])
	if(substr(house$p1[hrow],1,5) == substr(party[i],1,5)){
		oldHouse <- house$np1[hrow] / house$seats[hrow]
	} else {
		oldHouse <- house$np2[hrow] / house$seats[hrow]
	}
	if(substr(house$p1[hrow+1],1,5) == substr(party[i],1,5)){
		newHouse <- house$np1[hrow+1] / house$seats[hrow+1]
	} else {
		newHouse <- house$np2[hrow+1] / house$seats[hrow+1]
	}
	change[i] <- (newHouse - oldHouse)/oldHouse * 100
	presid[i] <- as.character(pres$potus[prow])
	unemp[i]  <- unempl$unemp[urow]
}

ump <- data.frame(year=year, 
                           potus=presid, 
                           party=party,
                           unemp=unemp, 
                           change=change)
ump[29, 3] <- "Democratic"
ump <- ump %>%
    mutate(party = factor(party, levels = c("Republican", "Democratic"))) %>%
    tibble()
```

```{r showdata, eval = FALSE}
ump
```

. . .

```{r ref.label = "showdata", echo = FALSE}
```


## Unemployment and elections, cont.

. . .

```{r echo = FALSE}
p1 <- ump %>%
    ggplot(aes(x = unemp, y = change, col = party)) +
    geom_point(size = 3) +
    theme_bw(base_size = 14) +
    xlab("Unemployment") +
    ylab("Percent change of seats in Congress") +
    scale_color_manual(values = c("red", "blue"))
m1 <- lm(change ~ unemp, data = ump)
```

```{r echo = FALSE}
p1
```

. . .

**Reigning theory**: voters will punish candidates from the Presidents party
at the ballot box when unemployment is high.


## Unemployment and elections, cont.

```{r echo=FALSE}
p1 +
  geom_abline(intercept = m1$coef[1], slope = m1$coef[2])
```

**Reigning theory**: voters will punish candidates from the Presidents party
at the ballot box when unemployment is high.


## Unemployment and elections, cont.

```{r echo=FALSE}
m1 <- lm(change ~ unemp, data = ump)
df2 <- ump %>%
    filter(unemp > 15)
p1 +
    geom_abline(intercept = m1$coef[1], slope = m1$coef[2]) +
    geom_point(data = df2, aes(x = unemp, y = change),
               shape = 1, col = "red", size = 6, lwd = 4)
```

**Reigning theory**: voters will punish candidates from the Presidents party
at the ballot box when unemployment is high.


## Unemployment and elections, cont. {.smaller}

. . .

```{r echo = FALSE}
library(dplyr)
ump <- filter(ump, unemp < 15)
m0 <- lm(change ~ unemp, data = ump)
p2 <- ump %>%
    ggplot(aes(x = unemp, y = change, col = party)) +
    geom_point(size = 3) +
    theme_bw(base_size = 14) +
    xlab("Unemployment") +
    ylab("Percent change of seats in Congress") +
    geom_abline(intercept = m0$coef[1], slope = m0$coef[2]) +
    scale_color_manual(values = c("red", "blue"))
p2
```

. . .

Focusing only on non-Great Depression elections, some evidence of a negative linear relationship between unemployment level and change in party support.

> _Or is there?_


## H-test for Regression

. . .

$H_0:$ There is no relationship between unemployment level and change in 
party support (or: change in party support is independent of unemployment).

$H_0: \beta_1 = 0$

. . .

### Method
If there is no relationship, the pairing between $X$ and $Y$ is
artificial and we can permute:

1. Generate synthetic data sets under $H_0$ by shuffling $X$.
2. Compute a new regression line for each data set and store each $b_1$.
3. See where your observed $b_1$ falls in the distribution of $b_1$'s under $H_0$.


## Your turn

::: poll
Take a moment to sketch out the infer pipeline that will results in a collection of 500 slopes that would might see in a world where the null hypothesis was true.

Turn to a neighbor and discuss your pipeline. I will ask for a pair to share.
:::

. . .

```{r}
ump
```

```{r echo = FALSE}
countdown::countdown(minutes = 3, warn_when = 20)
```


## {}

Take a moment to sketch out the infer pipeline that will results in a collection of 500 slopes that would might see in a world where the null hypothesis was true.

```{r eval = FALSE}
null <- ump %>%
  specify(change ~ unemp) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 500, type = "permute") %>%
  calculate(stat = "slope")
```


## First shuffle {auto-animate=true}

. . .

:::: columns
::: {.column width="47%"}
```{r echo=FALSE}
set.seed(30)
```

```{r shuf0, eval = FALSE}
library(infer)
ump %>%
  specify(change ~ unemp) %>%
  hypothesize(null = "independence") %>%
  generate(1, type = "permute")
```
:::
::::

## First shuffle {auto-animate=true}

:::: columns
::: {.column width="47%"}
```{r echo=FALSE}
set.seed(30)
```

```{r shuf1, eval = FALSE}
library(infer)
ump %>%
  specify(change ~ unemp) %>%
  hypothesize(null = "independence") %>%
  generate(1, type = "permute")
```

```{r ref.label = "shuf1", echo = FALSE}
```
:::
::::


## Second shuffle {auto-animate=true}

:::: columns
::: {.column width="47%"}
```{r echo=FALSE}
set.seed(30)
```

```{r}
library(infer)
ump %>%
  specify(change ~ unemp) %>%
  hypothesize(null = "independence") %>%
  generate(1, type = "permute")
```
:::
::: {.column width="6%"}
:::
::: {.column width="47%"}
```{r}
shuffle2 <- ump %>%
  specify(change ~ unemp) %>%
  hypothesize(null = "independence") %>%
  generate(1, type = "permute")
shuffle2
```
:::
::::


## Second shuffle, visualized {auto-animate=true}

```{r shufplot, eval = FALSE}
shuffle2 %>%
    ggplot(aes(x = unemp, y = change)) +
    geom_point(size = 3) +
    theme_bw(base_size = 14) +
    xlab("Unemployment") +
    ylab("Percent change of seats in Congress")
```

. . .

```{r ref.label = "shufplot", echo = FALSE, fig.height = 4.5}
```


## Second shuffle, visualized {auto-animate=true}

```{r shuf1lm, eval = FALSE, fig.height = 4.5}
#| code-line-numbers: "7"
shuffle2 %>%
    ggplot(aes(x = unemp, y = change)) +
    geom_point(size = 3) +
    theme_bw(base_size = 14) +
    xlab("Unemployment") +
    ylab("Percent change of seats in Congress") +
    stat_smooth(method = "lm", se = FALSE)
```

. . .

```{r ref.label = "shuf1lm", echo = FALSE, fig.height = 4.5}
#| code-line-numbers: "7"
```


## Third shuffle, visualized {auto-animate=true}

. . .

```{r echo = FALSE}
shuffle3 <- ump %>%
  specify(change ~ unemp) %>%
  hypothesize(null = "independence") %>%
  generate(1, type = "permute")
```

```{r shuf3lm, eval = FALSE, fig.height = 4.5}
#| code-line-numbers: "1"
shuffle3 %>%
    ggplot(aes(x = unemp, y = change)) +
    geom_point(size = 3) +
    theme_bw(base_size = 14) +
    xlab("Unemployment") +
    ylab("Percent change of seats in Congress") +
    stat_smooth(method = "lm", se = FALSE)
```

```{r ref.label = "shuf3lm", echo = FALSE, fig.height = 4.5}
```


## Fourth shuffle, visualized {auto-animate=true}

```{r echo = FALSE}
set.seed(166)
shuffle4 <- ump %>% 
  specify(change ~ unemp) %>%
  hypothesize(null = "independence") %>%
  generate(1, type = "permute")
```

```{r fig.height = 4.5}
#| code-line-numbers: "1"
shuffle4 %>%
    ggplot(aes(x = unemp, y = change)) +
    geom_point(size = 3) +
    theme_bw(base_size = 14) +
    xlab("Unemployment") +
    ylab("Percent change of seats in Congress") +
    stat_smooth(method = "lm", se = FALSE)
```


## Visualize 15 permuted $b_1$'s

```{r echo = FALSE, eval = FALSE}
library(gganimate)
library(transformr)
p <- ump %>%
    specify(change ~ unemp) %>%
    hypothesize(null = "independence") %>%
    generate(reps = 15, type = "permute") %>%
    ggplot(aes(x = unemp, y = change)) +
    geom_point(size = 3) + 
    theme_bw(base_size = 14) +
    geom_smooth(method = "lm",
                se = FALSE) +
    transition_states(replicate,
                      transition_length = 2,
                      state_length = 1) +
    ease_aes('cubic-in-out') +
    shadow_mark(alpha = .2, 
                color = "lightgrey",
                exclude_layer = "geom_point")

anim <- animate(p,
                nframes = 500,
                fps = 20,
                height = 4.5,
                width = 8, 
                unit = "in", 
                res = 150)
anim_save("many-slopes.gif", anim)
```

```{r echo = FALSE, eval = TRUE, fig.align='center', out.width="60%"}
knitr::include_graphics("images/many-slopes.gif")
```


## Generate 500 permuted $b_1$'s

. . .

```{r echo = FALSE}
set.seed(13)
```


```{r null, eval = FALSE}
null <- ump %>%
  specify(change ~ unemp) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 500, type = "permute") %>%
  calculate(stat = "slope")
null
```

. . .

```{r ref.label = "null", echo = FALSE}
```


## Visualize 500 permuted $b_1$'s

. . .

```{r compute, echo = FALSE, cache=TRUE}
line_df <- data.frame(matrix(rep(0, 200), ncol = 2))
ump_shuffled <- ump
for (i in 1:100) {
  ump_shuffled$unemp <- sample(ump$unemp)
  m1 <- lm(change ~ unemp, data = ump_shuffled)
  line_df[i, ] <- c(m1$coef)
}
```

```{r compute2, echo = FALSE}
p <- ump %>%
    ggplot(aes(x = unemp, y = change, col = party)) +
    geom_point(size = 3) +
    theme_bw(base_size = 14) +
    xlab("Unemployment") +
    ylab("Percent change of seats in Congress") +
    scale_color_manual(values = c("red", "blue"))

for (i in 1:100) {
  p <- p + geom_abline(intercept = line_df[i, 1], slope = line_df[i, 2],
                       alpha = .1)
}

p
```


## Null dist. of $b_1$

. . .

```{r echo = FALSE}
obs_slope <- ump %>%
  specify(change ~ unemp) %>%
  calculate(stat = "slope")
```

```{r nullvis, eval = FALSE}
null %>%
    visualize() +
    shade_p_value(obs_stat = obs_slope,
                  direction = "both")
```

. . .

```{r ref.label = "nullvis", echo = FALSE, message = FALSE, fig.height = 3.8}
```

. . .

**Reigning theory**: voters will punish candidates from the Presidents party
at the ballot box when unemployment is high.


## Null dist. of $b_1$, cont.

. . .

```{r pval, eval = FALSE}
null %>%
    get_p_value(obs_stat = obs_slope,
                direction = "both")
```

. . .

```{r ref.label="pval", echo = FALSE}
```


## H-tests for regression

. . .

```{r}
m0 <- lm(change ~ unemp, data = ump)
summary(m0)
```


## H-tests for regression

- Each line in the summary table is a hypothesis test that the parameter is zero.
- The summary table from `lm()` will always report p-values associated with a _t test_, regardless of if it's appropriate. `r emo::ji("grimace")`
- Under certain conditions, the test statistic associated with $b$'s is distributed 
like $t$ random variables with $n - p$ degrees of freedom.

. . .

$$ \frac{b - \beta}{SE} \sim t_{df = n - p}$$

. . .

```{r}
t_stat <- (-1.0010 - 0)/0.8717
pt(t_stat, df = 27 - 2) * 2
```


## Conditions for using the $t$ distribution for $b_1$

1. **Linearity**: linear trend between $X$ and $Y$, check with residual plot.
2. **Independent errors**: check with residual plot for serial correlation.
3. **Errors with constant variance**: look for constant spread in residual plot.
4. **Normally distributed errors**: look at histogram of residuals.


## Residuals vs $\hat{y}$

:::: columns
::: {.column width="50%"}
```{r resplot, eval = FALSE}
ump %>%
    mutate(res = residuals(m1),
           yhat = fitted(m1)) %>%
    ggplot(aes(x = yhat,
               y = res)) +
    geom_point() +
    geom_point(size = 3) +
    theme_bw(base_size = 14)
```
:::
::: {.column width="50%" .fragment}
```{r ref.label="resplot", echo = FALSE }
```
:::
::::

- Possible non-linear trend
- No sign of serial correlation
- No sign of non-constant variance


## Distribution of residuals

:::: columns
::: {.column width="50%"}
```{r resdist, eval = FALSE}
ump %>%
    mutate(res = residuals(m1),
           yhat = fitted(m1)) %>%
    ggplot(aes(x = res)) +
    geom_histogram() +
    theme_bw(base_size = 14)
```
:::
::: {.column width="50%"}
```{r ref.label="resdist", echo = FALSE }
```
:::
::::

. . .

- Possibly not normal

. . .

> So why were the p-values similar?


## H-tests for regression

- At small sample sizes, p-values and CIs based on the t-distribution require normal errors to be perfectly accurate, but are quite _robust_ to violations of that assumption.
- At large sample sizes the normality assumption becomes less important as the Central Limit Theorem takes over (the $t$ converges to the standard normal at large $n$).
- Permutation and bootstrap methods are always an option but they also require reasonable sample sizes to be accurate.


## {}

```{r echo = FALSE, fig.align = "center"}
knitr::include_graphics("images/538-3.png")
```
